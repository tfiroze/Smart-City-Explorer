{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d282b2d",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d16729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy as sqla\n",
    "import pickle\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pymysql\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Load pre-trained word embeddings (e.g., spaCy's medium English model)\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "from shapely.ops import nearest_points\n",
    "import geopandas as gpd\n",
    "from shapely import wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf165be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venue_static = pd.read_csv('venue_static.csv')\n",
    "df_venue_timings = pd.read_csv('venue_timings.csv')\n",
    "df_venue_merged = pd.read_csv('venue_merged.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5810f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venue_static = df_venue_static[df_venue_static['venue_type'] != 'LIBRARY']\n",
    "df_venue_static.to_csv('venue_static.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ca397e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manhattan_zone = pd.read_csv('./manhattan_zones.csv')\n",
    "#df_manhattan_zone.head(50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e84e1ef",
   "metadata": {},
   "source": [
    "# Manipulate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f471e79",
   "metadata": {},
   "source": [
    "## Split into Hour and Day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2b31d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venue_merged['merged_time'] = pd.to_datetime(df_venue_merged['merged_time'])\n",
    "\n",
    "# Add 'day_of_week' column (Monday as 0)\n",
    "df_venue_merged['day_of_week'] = df_venue_merged['merged_time'].dt.dayofweek\n",
    "\n",
    "# Add 'hour_integer' column\n",
    "df_venue_merged['hour_integer'] = df_venue_merged['merged_time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ab6ae57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(df_venue_merged.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78812016",
   "metadata": {},
   "source": [
    "## Grouping Venue Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e18f1e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_mapping = {\n",
    "    'PARK': 'Park',\n",
    "    'TOURIST_DESTINATION': 'Tourist Destination',\n",
    "    'MUSEUM': 'Cultural Heritage',\n",
    "    'HISTORICAL':'Cultural Heritage',\n",
    "    'SCENIC_POINT': 'Scenic Landmarks',\n",
    "    'BRIDGE': 'Scenic Landmarks',\n",
    "    'NATURE_RESERVE': 'Nature Attractions',\n",
    "    'ZOO': 'Nature Attractions',\n",
    "    'BOTANICAL_GARDEN': 'Nature Attractions',\n",
    "    'ARTS': 'Art',\n",
    "    'DESSERT':'Art',\n",
    "    'CHURCH': 'Religious',\n",
    "    'SYNAGOGUE':'Religious',\n",
    "    'VISITOR_CENTER': 'Tourist Destination',\n",
    "    'LIBRARY':'Library',\n",
    "    'SHOPPING_CENTER': 'Shopping Center',\n",
    "    'APPAREL':'Fashion Convenience',\n",
    "    'OTHER': 'Tourist Destination',\n",
    "    'SHOPPING': 'Fashion Convenience',\n",
    "    'CONVENIENCE_STORE':'Neighborhood Market',\n",
    "    'SUPERMARKET': 'Neighborhood Market',\n",
    "    'GROCERY':'Neighborhood Market',\n",
    "    'MARKET':'Neighborhood Market',\n",
    "    'GIFTS': 'Gifts & Souvenirs',\n",
    "    'SOUVENIR_SHOP':'Gifts & Souvenirs',\n",
    "    \n",
    "}\n",
    "\n",
    "df_venue_static['venue_mod_type'] = df_venue_static['venue_type'].replace(venue_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d77b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_to_zone_dict = {}\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in df_venue_static.iterrows():\n",
    "    venue_type = row['venue_mod_type']\n",
    "    zone = row['zone_id']\n",
    "    \n",
    "    # If the venue_type is already in the dictionary, append the zone to its list\n",
    "    if venue_type in venue_to_zone_dict:\n",
    "        venue_to_zone_dict[venue_type].append(zone)\n",
    "    # If the venue_type is not in the dictionary, create a new entry with the zone as a list\n",
    "    else:\n",
    "        venue_to_zone_dict[venue_type] = [zone]\n",
    "\n",
    "#print(venue_to_zone_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "202966d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_venue_static.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd513591",
   "metadata": {},
   "source": [
    "# Clearing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "956cabca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for duplicates\n",
    "#print('Number of duplicate (excluding first) rows in the table is: ', df_venue_static.duplicated().sum())\n",
    "\n",
    "# use \"keep=False\" to mark all duplicates as true, including the original rows that were duplicated\n",
    "#print('Number of duplicate rows (including first) in the table is:', df_venue_static[df_venue_static.duplicated(keep=False)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51881083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for duplicates\n",
    "#print('Number of duplicate (excluding first) rows in the table is: ', df_venue_timings.duplicated().sum())\n",
    "\n",
    "# use \"keep=False\" to mark all duplicates as true, including the original rows that were duplicated\n",
    "#print('Number of duplicate rows (including first) in the table is:', df_venue_timings[df_venue_timings.duplicated(subset=['venue_id', 'day', 'opening_time', 'closing_time'], keep='first')].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82dee57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Number of duplicate (excluding first) rows in the table is: ', df_venue_timings.drop_duplicates(subset=['venue_id', 'day', 'opening_time', 'closing_time'], inplace=True))\n",
    "#df_venue_timings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a1268",
   "metadata": {},
   "source": [
    "# Grouping Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6651ea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_zone_grouping = {\n",
    "    'Upper Manhattan': [128, 127, 243, 120, 244, 116, 42, 152, 41, 74, 75],\n",
    "    'Upper West Side': [166, 24, 151, 43, 238, 239, 143, 142],\n",
    "    'Upper East Side': [236,263, 262, 237, 141, 140 ],\n",
    "    'Chelsea/Greenwhich market':[246, 68, 186, 90, 100, 234, 158, 249, 113, 249],\n",
    "    'Lower Manhattan': [107, 224, 114, 211, 144, 148, 232, 231, 45, 13, 261, 209, 87, 88, 12 ],\n",
    "    'Midtown Manhattan': [50, 48, 230, 163, 161, 162, 229, 233, 164, 170, 137, 224, 107, 234]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc59c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# venue_zone_grouping dictionary\n",
    "venue_zone_grouping = {\n",
    "    'Upper Manhattan': [128, 127, 243, 120, 244, 116, 42, 152, 41, 74, 75],\n",
    "    'Upper West Side': [166, 24, 151, 43, 238, 239, 143, 142],\n",
    "    'Upper East Side': [236, 263, 262, 237, 141, 140],\n",
    "    'Chelsea/Greenwhich market': [246, 68, 186, 90, 100, 234, 158, 249, 113, 249],\n",
    "    'Lower Manhattan': [107, 224, 114, 211, 144, 148, 232, 231, 45, 13, 261, 209, 87, 88, 12],\n",
    "    'Midtown Manhattan': [50, 48, 230, 163, 161, 162, 229, 233, 164, 170, 137, 224, 107, 234],\n",
    "}\n",
    "\n",
    "# Function to map zone numbers to zone groups\n",
    "def map_zone_group(zone_number):\n",
    "    for zone_group, zone_numbers in venue_zone_grouping.items():\n",
    "        if zone_number in zone_numbers:\n",
    "            return zone_group\n",
    "    return 'Other'  # If zone number not found in the dictionary, assign 'Other'\n",
    "\n",
    "# Create the 'zone_group' column based on the mapping\n",
    "df_venue_static['zone_group'] = df_venue_static['zone_id'].apply(map_zone_group)\n",
    "\n",
    "#print(df_venue_static)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b852085",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venue_static.to_csv('zone_Grouping.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7304da8b",
   "metadata": {},
   "source": [
    "# Extracting Only Attratcion Types and Ignoring Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3f2309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_type_values = df_venue_static['venue_mod_type'].unique()\n",
    "#unique_type_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae74f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_venue_types = ['Nature Attractions', 'Shopping Center', 'Tourist Destination', 'Cultural Heritage', 'Neighborhood Market', 'Fashion Convenience', 'Library', 'Scenic Landmarks', 'Art', 'Religious', 'Park', 'Gifts & Souvenirs']\n",
    "\n",
    "# Filter the DataFrame to only include rows with the specific venue types\n",
    "df_venue_static_att = df_venue_static[df_venue_static['venue_mod_type'].isin(specific_venue_types)]\n",
    "\n",
    "# Now 'filtered_df' contains only rows where the \"Attraction_Type\" is in the specified list\n",
    "#print(df_venue_static_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd3a574",
   "metadata": {},
   "source": [
    "# Actual Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774716c2",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ab6a459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Zones: ['Upper Manhattan', 'Midtown Manhattan']\n",
      "Selected Attractions: ['Fashion Convenience']\n"
     ]
    }
   ],
   "source": [
    "# Function to get user input with constraints\n",
    "def get_user_input(prompt, max_entries, existing_entries=[]):\n",
    "    # Replace underscores with spaces for existing entries\n",
    "    existing_entries = [entry.replace('_', ' ') for entry in existing_entries]\n",
    "    \n",
    "    user_input_list = []\n",
    "    for i in range(max_entries):\n",
    "        entry = input(f\"{prompt} {i+1}/{max_entries} (Leave empty to stop entering): \").strip()\n",
    "        \n",
    "        # Replace underscores with spaces for user's entry\n",
    "        entry = entry.replace('_', ' ')\n",
    "        \n",
    "        while entry in existing_entries or entry in user_input_list:\n",
    "            entry = input(f\"Invalid! {prompt} {i+1}/{max_entries} already entered. Please re-enter or leave empty to stop: \").strip()\n",
    "            \n",
    "            # Replace underscores with spaces again for the new entry\n",
    "            entry = entry.replace('_', ' ')\n",
    "            \n",
    "        if entry == \"\":\n",
    "            break\n",
    "        user_input_list.append(entry)\n",
    "    return user_input_list\n",
    "\n",
    "# Get zones\n",
    "# user_zone_input = get_user_input(\"Enter zone\", 2)\n",
    "user_zone_input = ['Upper Manhattan','Midtown Manhattan']\n",
    "\n",
    "# Get attractions\n",
    "# user_input_attractions = get_user_input(\"Enter attraction\", 4)\n",
    "user_input_attractions = ['Fashion Convenience']\n",
    "\n",
    "print(\"Selected Zones:\", user_zone_input)\n",
    "print(\"Selected Attractions:\", user_input_attractions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c91c9663",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unique_type_values_att' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(user_input_attractions) \u001b[39m<\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[0;32m      2\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(user_input_attractions)\n\u001b[1;32m----> 4\u001b[0m     updated_list \u001b[39m=\u001b[39m [num \u001b[39mfor\u001b[39;00m num \u001b[39min\u001b[39;00m unique_type_values_att \u001b[39mif\u001b[39;00m num \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m user_input_attractions]\n\u001b[0;32m      6\u001b[0m     \u001b[39m# Always include either 'Park', 'Scenic Landmark', or 'Tourist Destination' if not in user's input\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     core_attractions \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mPark\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mScenic Landmarks\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTourist Destination\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unique_type_values_att' is not defined"
     ]
    }
   ],
   "source": [
    "if len(user_input_attractions) < 4:\n",
    "    x = 4 - len(user_input_attractions)\n",
    "    \n",
    "    updated_list = [num for num in unique_type_values_att if num not in user_input_attractions]\n",
    "    \n",
    "    # Always include either 'Park', 'Scenic Landmark', or 'Tourist Destination' if not in user's input\n",
    "    core_attractions = ['Park', 'Scenic Landmarks', 'Tourist Destination']\n",
    "    \n",
    "    # Find out which core attractions are not in the user's input\n",
    "    missing_core_attractions = [attraction for attraction in core_attractions if attraction not in user_input_attractions]\n",
    "    \n",
    "    # Compute similarities only for missing core attractions\n",
    "    core_similarities = []\n",
    "    user_input_tag_embedding = nlp(user_input_attractions[0]).vector\n",
    "\n",
    "    for tag in missing_core_attractions:\n",
    "        tag_embedding = nlp(tag).vector\n",
    "        similarity = user_input_tag_embedding.dot(tag_embedding) / (np.linalg.norm(user_input_tag_embedding) * np.linalg.norm(tag_embedding))\n",
    "        core_similarities.append(similarity)\n",
    "\n",
    "    # Add the most similar core attraction to user's input\n",
    "    if core_similarities:\n",
    "        most_similar_core_index = np.argmax(core_similarities)\n",
    "        user_input_attractions.append(missing_core_attractions[most_similar_core_index])\n",
    "        x -= 1  # Decrement x as we've added a core attraction\n",
    "\n",
    "    # Now, for the remaining attractions (if any)\n",
    "    if x > 0:\n",
    "        other_similarities = []\n",
    "        \n",
    "        for tag in updated_list:\n",
    "            tag_embedding = nlp(tag).vector\n",
    "            similarity = user_input_tag_embedding.dot(tag_embedding) / (np.linalg.norm(user_input_tag_embedding) * np.linalg.norm(tag_embedding))\n",
    "            other_similarities.append(similarity)\n",
    "\n",
    "        sorted_indices = np.argsort(other_similarities)[::-1]  # Descending order\n",
    "        most_similar_tags = [updated_list[i] for i in sorted_indices]\n",
    "        slice_most_similar_tags = most_similar_tags[0:x]\n",
    "        user_input_attractions = user_input_attractions + slice_most_similar_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef30b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Art', 'Scenic Landmarks', 'Cultural Heritage', 'Gifts & Souvenirs']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input_attractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7324de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "priority_table = pd.DataFrame({\n",
    "    'Attraction': ['Park', 'Tourist Destination', 'Cultural Heritage', 'Scenic Landmarks', 'Nature Attractions',\n",
    "                   'Religious', 'Art',  'Shopping Center', 'Fashion Convenience',\n",
    "                   'Neighborhood Market', 'Gifts & Souvenirs'],\n",
    "    'Opening_Time': ['9:00 AM', '9:00 AM', '11:00 AM', '9:00 AM', '10:00 AM', '11:00 AM', '10:00 AM', \n",
    "                     '10:00 AM', '10:00 AM', '10:00 AM', '10:00 AM'],\n",
    "    'Closing_Time': ['6:00 PM', '6:00 PM', '5:00 PM', '11:00 PM', '4:00 PM', '5:00 PM', '5:00 PM', \n",
    "                     '6:00 PM', '6:00 PM', '6:00 PM', '6:00 PM']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04f7a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Attraction Opening_Time Closing_Time   Opening_Timestamp\n",
      "0                  Park      9:00 AM      6:00 PM 2023-08-07 09:00:00\n",
      "1   Tourist Destination      9:00 AM      6:00 PM 2023-08-07 09:00:00\n",
      "2     Cultural Heritage     11:00 AM      5:00 PM 2023-08-07 11:00:00\n",
      "3      Scenic Landmarks      9:00 AM     11:00 PM 2023-08-07 09:00:00\n",
      "4    Nature Attractions     10:00 AM      4:00 PM 2023-08-07 10:00:00\n",
      "5             Religious     11:00 AM      5:00 PM 2023-08-07 11:00:00\n",
      "6                   Art     10:00 AM      5:00 PM 2023-08-07 10:00:00\n",
      "7       Shopping Center     10:00 AM      6:00 PM 2023-08-07 10:00:00\n",
      "8   Fashion Convenience     10:00 AM      6:00 PM 2023-08-07 10:00:00\n",
      "9   Neighborhood Market     10:00 AM      6:00 PM 2023-08-07 10:00:00\n",
      "10    Gifts & Souvenirs     10:00 AM      6:00 PM 2023-08-07 10:00:00\n"
     ]
    }
   ],
   "source": [
    "# Assuming the following structure for df_venue_static_att: ['venue_id', 'venue_mod_type']\n",
    "\n",
    "# 1. Get the venue_id for each venue_mod_type from df_venue_static_att\n",
    "venue_ids_per_type = df_venue_static_att.groupby('venue_type')['hash_ven_id'].apply(list).to_dict()\n",
    "\n",
    "# 2. Use the venue_id to filter entries in df_venue_timings\n",
    "hourly_counts = {}\n",
    "for hour in range(24):  # 24 hours\n",
    "    for venue_type, venue_ids in venue_ids_per_type.items():\n",
    "        mask = (df_venue_timings['venue_id'].isin(venue_ids)) & \\\n",
    "               (df_venue_timings['opening_time'] <= hour) & \\\n",
    "               (df_venue_timings['closing_time'] >= hour) & \\\n",
    "               (df_venue_timings['day'] == 6)  # Assuming 6 represents Sunday\n",
    "        count = len(df_venue_timings[mask])\n",
    "        if venue_type not in hourly_counts:\n",
    "            hourly_counts[venue_type] = {}\n",
    "        hourly_counts[venue_type][hour] = count\n",
    "\n",
    "# 3. Determine most common opening and closing times\n",
    "common_times = {}\n",
    "for venue_type, counts in hourly_counts.items():\n",
    "    open_hour = min(counts.keys())\n",
    "    close_hour = max(counts.keys())\n",
    "    common_times[venue_type] = {\n",
    "        'Opening_Time': f'{open_hour}:00 AM' if open_hour < 12 else f'{open_hour-12 if open_hour > 12 else 12}:00 PM',\n",
    "        'Closing_Time': f'{close_hour}:00 AM' if close_hour < 12 else f'{close_hour-12 if close_hour > 12 else 12}:00 PM'\n",
    "    }\n",
    "\n",
    "# 4. Update the priority table\n",
    "for index, row in priority_table.iterrows():\n",
    "    attraction = row['Attraction']\n",
    "    if attraction in common_times:\n",
    "        priority_table.at[index, 'Opening_Time'] = common_times[attraction]['Opening_Time']\n",
    "        priority_table.at[index, 'Closing_Time'] = common_times[attraction]['Closing_Time']\n",
    "\n",
    "print(priority_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ee326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested Itinerary: {'Scenic Landmarks': '09:00 AM - 11:00 AM', 'Art': '11:00 AM - 01:00 PM', 'Gifts & Souvenirs': '03:00 PM - 05:00 PM', 'Cultural Heritage': '05:00 PM - 05:00 PM'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Sort attractions based on their opening times\n",
    "priority_table['Opening_Timestamp'] = pd.to_datetime(priority_table['Opening_Time'])\n",
    "sorted_attractions = priority_table.set_index('Attraction').loc[user_input_attractions].sort_values('Opening_Timestamp').index.tolist()\n",
    "\n",
    "# Initialize the itinerary dictionary\n",
    "itinerary = {}\n",
    "\n",
    "# Set the day's starting and ending time\n",
    "start_of_day = pd.Timestamp(f\"{current_date} 9:00 AM\")\n",
    "lunch_start = pd.Timestamp(f\"{current_date} 1:00 PM\")\n",
    "lunch_end = pd.Timestamp(f\"{current_date} 3:00 PM\")\n",
    "dinner_start = pd.Timestamp(f\"{current_date} 7:00 PM\")\n",
    "dinner_end = pd.Timestamp(f\"{current_date} 9:00 PM\")\n",
    "end_of_day = pd.Timestamp(f\"{current_date} 9:00 PM\")\n",
    "current_time = start_of_day\n",
    "\n",
    "for attraction in sorted_attractions:\n",
    "    row = priority_table[priority_table['Attraction'] == attraction].iloc[0]\n",
    "    opening_time = pd.Timestamp(f\"{current_date} {row['Opening_Time']}\")\n",
    "    closing_time = pd.Timestamp(f\"{current_date} {row['Closing_Time']}\")\n",
    "\n",
    "    # Skip if the attraction is already closed or will not open today\n",
    "    if current_time > closing_time or current_time < opening_time:\n",
    "        continue\n",
    "\n",
    "    # If it's lunchtime, jump to after lunch.\n",
    "    if lunch_start <= current_time < lunch_end:\n",
    "        current_time = lunch_end\n",
    "    \n",
    "    # If it's dinnertime, jump to after dinner.\n",
    "    if dinner_start <= current_time < dinner_end:\n",
    "        current_time = dinner_end\n",
    "\n",
    "    # Set the current time to the opening time if it's earlier\n",
    "    if current_time < opening_time:\n",
    "        current_time = opening_time\n",
    "\n",
    "    # Calculate the visit duration (min of 2 hours or available time)\n",
    "    visit_duration = min(2, (closing_time - current_time).seconds / 3600)\n",
    "\n",
    "    # Add to the itinerary if within the day's limit\n",
    "    if current_time + pd.Timedelta(hours=visit_duration) <= end_of_day:\n",
    "        itinerary[attraction] = f\"{current_time.strftime('%I:%M %p')} - {(current_time + pd.Timedelta(hours=visit_duration)).strftime('%I:%M %p')}\"\n",
    "        current_time += pd.Timedelta(hours=visit_duration)  # No buffer added here\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Print the suggested itinerary\n",
    "print(\"Suggested Itinerary:\", itinerary)\n",
    "itinerary_timing = itinerary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47262a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_group = []\n",
    "for group in user_zone_input:\n",
    "    for zone in venue_zone_grouping[group]:\n",
    "        zone_group.append(zone)\n",
    "#zone_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a367d3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Scenic Landmarks': [43, -1, 74], 'Art': [236, 230, 163], 'Gifts & Souvenirs': [161, 48, 230, 246, 234, 41, 163, 249, 100, 261, 170], 'Cultural Heritage': [43, 24, 163, 236, 239, 103, 162, 50, 170, 161, 151, 158, 230, 100, 238, 75, 142]}\n"
     ]
    }
   ],
   "source": [
    "zone_type_dict = {}\n",
    "for venue_type in itinerary_timing:\n",
    "    matched_zones = df_venue_static_att[df_venue_static_att['venue_mod_type'] == venue_type]['zone_id'].unique()\n",
    "    zone_type_dict[venue_type] = list(matched_zones)\n",
    "\n",
    "# Print the resulting dictionary\n",
    "print(zone_type_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6eccb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Scenic Landmarks': ['ven_344c563654744266547349526b6f7733506f68442d65734a496843', 'ven_6367354456587959525968526b6f77326a4172446665454a496843', 'ven_6764666e625a435a654552526b6f77316a645f693539314a496843', 'ven_67786f6559776463355574526b6f77326a414755372d7a4a496843', 'ven_6b655736786b3944445147526b6f77326e5173764f38384a496843', 'ven_776351756c436838704850526b6f773258776a4d3039654a496843'], 'Art': [], 'Gifts & Souvenirs': ['ven_345049646f62573761314b526b6f773254786a4e3765534a496843', 'ven_5149584e6b423237664c6b526b6f773248785f7a7356564a496843', 'ven_73384a356c42716a656576526b6f77616c684247547a624a496843'], 'Cultural Heritage': ['ven_6b68703776545f78704e31526b6f7732334274596834694a496843', 'ven_6f4a3437455573596f624c526b6f77324c414e756756504a496843', 'ven_734141687055567841634e526b6f77327a4255673054574a496843']}\n"
     ]
    }
   ],
   "source": [
    "user_venue_per_type_dict = {}\n",
    "for venue_type in itinerary_timing:\n",
    "    matched_zones = df_venue_static_att[df_venue_static_att['venue_mod_type'] == venue_type]['zone_id']\n",
    "    matching_zones = matched_zones[matched_zones.isin(zone_group)]\n",
    "    result_df = df_venue_static_att[df_venue_static_att['zone_id'].isin(matching_zones)]['original_ven_id']\n",
    "    user_venue_per_type_dict[venue_type] = list(result_df)\n",
    "\n",
    "# Print the resulting dictionary\n",
    "print(user_venue_per_type_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dcb287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Venue types with 0 zones: ['Art']\n"
     ]
    }
   ],
   "source": [
    "types_with_zero_zones = []\n",
    "\n",
    "# Iterate through the venue_type_dict\n",
    "for venue_type, zones in user_venue_per_type_dict.items():\n",
    "    if len(zones) == 0:\n",
    "        types_with_zero_zones.append(venue_type)\n",
    "\n",
    "print(\"Venue types with 0 zones:\", types_with_zero_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95946cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distance_between_zones(zone1_polygon, zone2_polygon):\n",
    "    # Find the nearest points between the two polygons\n",
    "    nearest_points_result = nearest_points(wkt.loads(zone1_polygon), wkt.loads(zone2_polygon))\n",
    "\n",
    "    # Calculate the distance between the nearest points\n",
    "    distance = nearest_points_result[0].distance(nearest_points_result[1])\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d0ee8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Art': ['ven_45566b4479733438494a61526b6f775952704d3242546a4a496843']}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_type_with_zero_zone = {}\n",
    "\n",
    "for ven_type in types_with_zero_zones:\n",
    "    venue_to_zone_dict_copy = list(set(venue_to_zone_dict[ven_type]))\n",
    "    \n",
    "    if len(venue_to_zone_dict_copy) <= 0: # Modified condition\n",
    "        #get all venue id of each zone and push it to user_venue_per_type_dict of that type\n",
    "        print('okay')\n",
    "        continue  # Continue to next iteration of the loop\n",
    "    \n",
    "    zone_between_dist = []\n",
    "    for user_zone in zone_group:\n",
    "        for venue_zone in venue_to_zone_dict_copy:\n",
    "            zone1_polygon = df_manhattan_zone[df_manhattan_zone['LocationID'] == user_zone]['the_geom'].iloc[0]\n",
    "            zone2_polygon = df_manhattan_zone[df_manhattan_zone['LocationID'] == venue_zone]['the_geom'].iloc[0]\n",
    "            distance = find_distance_between_zones(zone1_polygon, zone2_polygon)\n",
    "            zone_between_dist.append((user_zone, venue_zone, distance)) \n",
    "\n",
    "    sorted_zone_between_dist = sorted(zone_between_dist, key=lambda x: x[2])[:3]\n",
    "    new_zone = [df_venue_static_att[\n",
    "        (df_venue_static_att['zone_id'] == item[1]) &\n",
    "        (df_venue_static_att['venue_mod_type'] == ven_type)\n",
    "    ]['original_ven_id'].tolist() for item in sorted_zone_between_dist]\n",
    "    \n",
    "    filled_type_with_zero_zone[ven_type] = list(set(item for sublist in new_zone for item in sublist))\n",
    "\n",
    "filled_type_with_zero_zone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdfa136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Scenic Landmarks': ['ven_344c563654744266547349526b6f7733506f68442d65734a496843', 'ven_6367354456587959525968526b6f77326a4172446665454a496843', 'ven_6764666e625a435a654552526b6f77316a645f693539314a496843', 'ven_67786f6559776463355574526b6f77326a414755372d7a4a496843', 'ven_6b655736786b3944445147526b6f77326e5173764f38384a496843', 'ven_776351756c436838704850526b6f773258776a4d3039654a496843'], 'Art': ['ven_45566b4479733438494a61526b6f775952704d3242546a4a496843'], 'Gifts & Souvenirs': ['ven_345049646f62573761314b526b6f773254786a4e3765534a496843', 'ven_5149584e6b423237664c6b526b6f773248785f7a7356564a496843', 'ven_73384a356c42716a656576526b6f77616c684247547a624a496843'], 'Cultural Heritage': ['ven_6b68703776545f78704e31526b6f7732334274596834694a496843', 'ven_6f4a3437455573596f624c526b6f77324c414e756756504a496843', 'ven_734141687055567841634e526b6f77327a4255673054574a496843']}\n"
     ]
    }
   ],
   "source": [
    "for key in user_venue_per_type_dict.keys():\n",
    "    # Check if the value of the current key is an empty array\n",
    "    if len(user_venue_per_type_dict[key]) == 0:\n",
    "        # Check if the key exists in dictionary B\n",
    "        if key in filled_type_with_zero_zone:\n",
    "            # Replace the value in A with the value from B\n",
    "            user_venue_per_type_dict[key] = filled_type_with_zero_zone[key]\n",
    "print(user_venue_per_type_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e48c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Scenic Landmarks': ['ven_344c563654744266547349526b6f7733506f68442d65734a496843', 'ven_67786f6559776463355574526b6f77326a414755372d7a4a496843'], 'Art': ['ven_45566b4479733438494a61526b6f775952704d3242546a4a496843'], 'Gifts & Souvenirs': ['ven_345049646f62573761314b526b6f773254786a4e3765534a496843', 'ven_5149584e6b423237664c6b526b6f773248785f7a7356564a496843', 'ven_73384a356c42716a656576526b6f77616c684247547a624a496843'], 'Cultural Heritage': ['ven_6b68703776545f78704e31526b6f7732334274596834694a496843']}\n"
     ]
    }
   ],
   "source": [
    "# ... [Other necessary imports, data, and current_date definition]\n",
    "\n",
    "# ... [Your code for generating the itinerary]\n",
    "\n",
    "# Now, for the venues\n",
    "filtered_venues = {}\n",
    "\n",
    "today_day_num = datetime.now().weekday()  # 0: Monday, 6: Sunday\n",
    "\n",
    "# Using the itinerary timings:\n",
    "for attraction, timing in itinerary.items():\n",
    "    start_time, end_time = [t.strip() for t in timing.split('-')]\n",
    "    start_hour = int(pd.Timestamp(f\"{current_date} {start_time}\").strftime('%H'))\n",
    "    end_hour = int(pd.Timestamp(f\"{current_date} {end_time}\").strftime('%H'))\n",
    "\n",
    "    valid_venues = []\n",
    "    for venue_id in user_venue_per_type_dict.get(attraction, []):  # Only work with venues in user input\n",
    "        venue_info = df_venue_timings.loc[df_venue_timings['venue_id'] == venue_id]\n",
    "        \n",
    "        # Check if the venue is closed for the day\n",
    "        if venue_info['opening_time'].iloc[0] == -1 or venue_info['closing_time'].iloc[0] == -1:\n",
    "            continue\n",
    "\n",
    "        filtered_venue_info = venue_info.loc[(venue_info['day'] == today_day_num) \n",
    "                                             & (venue_info['opening_time'] <= start_hour)\n",
    "                                             & (venue_info['closing_time'] >= end_hour)]\n",
    "        if not filtered_venue_info.empty:\n",
    "            valid_venues.append(venue_id)\n",
    "                \n",
    "    if valid_venues:\n",
    "        filtered_venues[attraction] = valid_venues\n",
    "\n",
    "print(filtered_venues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fb87b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulated_venues = {}\n",
    "\n",
    "# Loop through each venue type and check for the specified condition\n",
    "for venue_type, venue_ids in filtered_venues.items():\n",
    "    valid_venues = []\n",
    "    for venue_id in venue_ids:\n",
    "        venue_hash_id = df_venue_static.loc[df_venue_static['original_ven_id'] == venue_id]['hash_ven_id']\n",
    "        venue_rating = df_venue_static.loc[df_venue_static['original_ven_id'] == venue_id]['rating'].item()\n",
    "        venue_hash_id = int(venue_hash_id)\n",
    "        df_venue_merged['venue_id'] = df_venue_merged['venue_id'].astype(int)\n",
    "        specific_venue_df = df_venue_merged.loc[df_venue_merged['venue_id'] == venue_hash_id]\n",
    "        average_busyness = specific_venue_df['busyness'].mean() \n",
    "        \n",
    "        weight_rating = 0.6\n",
    "        weight_busyness = 0.4\n",
    "        composite_score = (weight_rating * venue_rating) + (weight_busyness * average_busyness)\n",
    "        \n",
    "        \n",
    "        valid_venues.append((venue_id, venue_rating, average_busyness, composite_score))\n",
    "    if valid_venues:\n",
    "        manipulated_venues[venue_type] = valid_venues\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e9ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Venue Type: Scenic Landmarks\n",
      "Rank 1: Venue ID: ven_344c563654744266547349526b6f7733506f68442d65734a496843, Rating: 4.4, Busyness: 22.606060606060606, Score: 11.682424242424243\n",
      "Rank 2: Venue ID: ven_67786f6559776463355574526b6f77326a414755372d7a4a496843, Rating: 4.3, Busyness: 31.856060606060606, Score: 15.322424242424242\n",
      "\n",
      "Venue Type: Art\n",
      "Rank 1: Venue ID: ven_45566b4479733438494a61526b6f775952704d3242546a4a496843, Rating: 4.6, Busyness: 9.803030303030303, Score: 6.681212121212122\n",
      "\n",
      "Venue Type: Gifts & Souvenirs\n",
      "Rank 1: Venue ID: ven_345049646f62573761314b526b6f773254786a4e3765534a496843, Rating: 4.2, Busyness: 7.9772727272727275, Score: 5.710909090909091\n",
      "Rank 2: Venue ID: ven_5149584e6b423237664c6b526b6f773248785f7a7356564a496843, Rating: 4.7, Busyness: 12.431818181818182, Score: 7.792727272727273\n",
      "Rank 3: Venue ID: ven_73384a356c42716a656576526b6f77616c684247547a624a496843, Rating: 4.5, Busyness: 6.356060606060606, Score: 5.242424242424242\n",
      "\n",
      "Venue Type: Cultural Heritage\n",
      "Rank 1: Venue ID: ven_6b68703776545f78704e31526b6f7732334274596834694a496843, Rating: 4.5, Busyness: 15.113636363636363, Score: 8.745454545454546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_3_venues = {}\n",
    "\n",
    "# Loop through each venue type and its venues\n",
    "for venue_type, venue_data in manipulated_venues.items():\n",
    "    # Sort the venues based on the composite score (fourth element in the tuple, index 3)\n",
    "    if len(venue_data) > 3:\n",
    "        sorted_venues = sorted(venue_data, key=lambda x: x[3], reverse=True)\n",
    "    \n",
    "        # Keep only the top 3 venues for each venue type\n",
    "        top_3_venues[venue_type] = sorted_venues[:3]\n",
    "    else:\n",
    "        top_3_venues[venue_type] = venue_data\n",
    "\n",
    "# Display the top 3 venues for each venue type\n",
    "for venue_type, top_venues in top_3_venues.items():\n",
    "    print(f\"Venue Type: {venue_type}\")\n",
    "    for rank, (venue_id, rating, busyness, score) in enumerate(top_venues, start=1):\n",
    "        print(f\"Rank {rank}: Venue ID: {venue_id}, Rating: {rating}, Busyness: {busyness}, Score: {score}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
